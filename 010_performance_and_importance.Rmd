---
title: "measure performance and feature importances with DALEX + mlr"
author: "Satoshi Kato"
date: "`r format(Sys.time(), '%Y/%m/%d')`"
output:
  html_document:
    fig_caption: yes
    pandoc_args:
    - --from
    - markdown+autolink_bare_uris+tex_math_single_backslash-implicit_figures
    toc: yes
    toc_depth: 4
    keep_md: yes
  word_document:
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
require(tidyverse)
require(mlr)
require(iml)

knitr::opts_knit$set(progress = TRUE, 
                     verbose = TRUE, 
                     root.dir = ".")

knitr::opts_chunk$set(collapse = FALSE, 
                      prompt  = FALSE,
                      comment = "", 
                      message = TRUE, 
                      warning = FALSE, 
                      echo=TRUE)
set.seed(12345)
```

# read mlr models

regression task for apartments dataset.

```{r mlr.prep, message=FALSE}
tuned.model <- readRDS("./tuned_models.RDS")
# tuned.model %>% str(2)

```

# DALEX + mlr

according to:

https://rawgit.com/pbiecek/DALEX_docs/master/vignettes/DALEX_mlr.html

# The explain() function

## custom predict()

For the models created by mlr package we have to provide custom predict function which takes two arguments: model and newdata and returns a numeric vector with predictions because function predict() from mlr returns not only predictions but an object with more information.

```{r}
predictMLR <- function(object, newdata) {
  pred <- predict(object, newdata=newdata)
  response <- pred$data$response
  return(response)
}

```

# build explainer

## simple

```{r}
require(DALEX)
data("apartmentsTest", package = "DALEX")

model.regr.rf <- tuned.model[["rf"]]

explainer <- list()
explainer.rf <-  explain(model = model.regr.rf, 
                         label = "rf",
                         data  = apartmentsTest %>% select(-m2.price), 
                         y     = apartmentsTest$m2.price,
                         predict_function = predictMLR)

```

## multiple explainers

```{r}
model.labels <- names(tuned.model)
model.regr   <- list()

for(model.name in model.labels){
  model.regr[[model.name]] <- tuned.model[[model.name]]
  
  explainer[[model.name]] <- explain(model = model.regr[[model.name]], 
                                     label = model.name,
                                     data  = apartmentsTest %>% select(-m2.price), 
                                     y     = apartmentsTest$m2.price,
                                     predict_function = predictMLR)
}

```


# measure model performance

## simple

Empirical Cumulative Distribution Function (ecdf) of residual error is as default.

```{r}
mp <- model_performance(explainer.rf)
str(mp)
plot(mp)
plot(mp, geom = "boxplot")
```

## model comparison

```{r}
mps <- list()
for(model.name in model.labels){
  mps[[model.name]] <- model_performance(explainer[[model.name]])
}
plot(mps[["enet"]], 
     mps[["svm"]], 
     mps[["rf"]], 
     mps[["gbm"]])

plot(geom = "boxplot",
     mps[["enet"]], 
     mps[["svm"]], 
     mps[["rf"]], 
     mps[["gbm"]])
```

# Variable importance

## simple

`type="raw"` is as default.

```{r}
var.imp <- variable_importance(explainer     = explainer.rf, 
                               loss_function = loss_root_mean_square)
plot(var.imp)
print(var.imp)

```

## set baseline from fullmodel

For better comparison of the models we can hook the variabe importance at 0 using the type="difference", returns `drop_loss - drop_loss_full_model`.

```{r}
var.imp.diff <- variable_importance(explainer     = explainer.rf,
                                    loss_function = loss_root_mean_square,
                                    type          = "difference")

plot(var.imp.diff)
```

## model comparison


```{r fig.height=8, fig.width=6}
vid <- list()
pvid <- list()
for(model.name in model.labels){
  vid[[model.name]] <- variable_importance(explainer     = explainer[[model.name]],
                                           loss_function = loss_root_mean_square,
                                           type          = "difference")
  pvid[[model.name]] <- plot(vid[[model.name]])
}

plot(vid[["enet"]], 
     vid[["svm"]], 
     vid[["rf"]], 
     vid[["gbm"]])

# gridExtra::grid.arrange(grobs = pvid)

```
